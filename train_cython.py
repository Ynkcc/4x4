# /home/ynk/Desktop/banqi/4x4/gym/train_cython.py

import os
import time
import gymnasium as gym
import numpy as np
import torch as th

from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.vec_env import DummyVecEnv
from stable_baselines3.common.callbacks import BaseCallback
# from sb3_contrib.common.maskable.policies import MaskableActorCriticPolicy
# from sb3_contrib.common.wrappers import ActionMasker
# from sb3_contrib.ppo_mask import MaskablePPO

# å¯¼å…¥ Cython ä¼˜åŒ–çš„ç¯å¢ƒ
try:
    from Game_cython import BanqiEnvironment
    cython_env_available = True
    print("âœ“ Game_cython.BanqiEnvironment æ¨¡å—å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âœ— Game_cython.BanqiEnvironment æ¨¡å—å¯¼å…¥å¤±è´¥: {e}")
    cython_env_available = False

# ä½¿ç”¨æ ‡å‡† PPO è€Œä¸æ˜¯ MaskablePPO æ¥é¿å…ç±»å‹é”™è¯¯
from stable_baselines3 import PPO
from stable_baselines3.common.policies import ActorCriticPolicy

# æ£€æŸ¥ PyTorch æ˜¯å¦å¯ç”¨
try:
    import torch
    print("âœ“ PyTorch å¯ç”¨ï¼Œæ”¯æŒè‡ªå®šä¹‰ç½‘ç»œæ¶æ„")
except ImportError:
    print("âœ— PyTorch æœªå®‰è£…ï¼Œæ— æ³•ä½¿ç”¨è‡ªå®šä¹‰ç½‘ç»œæ¶æ„")

# [å…³é”®ä¿®æ”¹] ä½¿ç”¨ä¸€ä¸ªæ›´å¥å£®çš„å›è°ƒå‡½æ•°
class StatsCallback(BaseCallback):
    """
    ä¸€ä¸ªæ›´å¥å£®çš„å›è°ƒå‡½æ•°ï¼Œç”¨äºè®°å½•å’Œæ‰“å°æ¯100ä¸ªå›åˆçš„å¹³å‡å¥–åŠ±å’Œé•¿åº¦ã€‚
    """
    def __init__(self, verbose=0):
        super(StatsCallback, self).__init__(verbose)
        self.episode_rewards = []
        self.episode_lengths = []

    def _on_step(self) -> bool:
        # æ£€æŸ¥æ˜¯å¦æœ‰å›åˆç»“æŸ
        # self.locals['dones'] æ˜¯ä¸€ä¸ªå¸ƒå°”æ•°ç»„ï¼Œå¯¹åº”æ¯ä¸ªå¹¶è¡Œç¯å¢ƒ
        if "dones" in self.locals:
            for i, done in enumerate(self.locals["dones"]):
                if done:
                    # å¦‚æœä¸€ä¸ªç¯å¢ƒçš„å›åˆç»“æŸï¼Œä»infoå­—å…¸ä¸­æå–ç»Ÿè®¡ä¿¡æ¯
                    # Monitor wrapper ä¼šè‡ªåŠ¨æ·»åŠ  'episode' é”®
                    info = self.locals["infos"][i]
                    if "episode" in info:
                        self.episode_rewards.append(info["episode"]["r"])
                        self.episode_lengths.append(info["episode"]["l"])

        # å½“æ”¶é›†åˆ°è¶³å¤Ÿçš„æ•°æ®æ—¶ï¼ˆä¾‹å¦‚100ä¸ªå›åˆï¼‰ï¼Œè®°å½•æ—¥å¿—
        if len(self.episode_rewards) >= 100:
            mean_reward = np.mean(self.episode_rewards)
            mean_length = np.mean(self.episode_lengths)
            
            self.logger.record("rollout/ep_rew_mean_100", mean_reward)
            self.logger.record("rollout/ep_len_mean_100", mean_length)
            
            # æ‰“å°åˆ°æ§åˆ¶å°ä»¥ä¾¿è§‚å¯Ÿ
            if self.verbose > 0:
                print(f"Logged stats for 100 episodes. Mean Reward: {mean_reward:.4f}, Mean Length: {mean_length:.1f}")

            # æ¸…ç©ºç¼“å†²åŒºä»¥ä¾¿ä¸‹ä¸€æ¬¡è®¡ç®—
            self.episode_rewards.clear()
            self.episode_lengths.clear()

        return True

def get_env_creator(env_class, env_kwargs=None):
    """è¿”å›ä¸€ä¸ªåˆ›å»ºå’ŒåŒ…è£…ç¯å¢ƒçš„å‡½æ•°ã€‚"""
    if env_kwargs is None:
        env_kwargs = {}
    
    def _init():
        env = env_class(**env_kwargs)
        # ç¡®ä¿ RecordEpisodeStatistics wrapper è¢«åº”ç”¨ï¼Œä»¥ä¾¿åœ¨ info ä¸­è·å¾— 'episode' ä¿¡æ¯
        env = gym.wrappers.RecordEpisodeStatistics(env)
        # æš‚æ—¶æ³¨é‡Šæ‰ ActionMasker ä»¥æ’é™¤é—®é¢˜
        # env = ActionMasker(env, gym.spaces.Box)
        return env
    
    return _init

def main():
    # å®šä¹‰è¶…å‚æ•°
    total_timesteps = 5_000_000
    n_steps = 2048
    n_envs = 8

    # è®­ç»ƒæ—¥å¿—å’Œæ¨¡å‹ä¿å­˜è·¯å¾„
    log_dir = "./banqi_cython_ppo_logs"
    model_save_path = os.path.join(log_dir, "banqi_cython_model.zip")
    os.makedirs(log_dir, exist_ok=True)
    
    if not cython_env_available:
        print("é”™è¯¯ï¼šCython ç¯å¢ƒä¸å¯ç”¨ï¼Œè¯·å…ˆç¼–è¯‘ .pyx æ–‡ä»¶ã€‚")
        return

    print("--- å¯ç”¨ 8 ä¸ª Cython ä¼˜åŒ–çš„ä¸²è¡Œç¯å¢ƒè¿›è¡Œæ•°æ®æ”¶é›† (ä½¿ç”¨ DummyVecEnv) ---")
    print("--- ä½¿ç”¨ Game_cython.BanqiEnvironment (Gymnasium å…¼å®¹åŒ…è£…å™¨) ---")
    
    env_creator = get_env_creator(BanqiEnvironment)
    vec_env = make_vec_env(env_creator, n_envs=n_envs, vec_env_cls=DummyVecEnv)

    # æ£€æŸ¥æ˜¯å¦æœ‰å·²å­˜åœ¨çš„æ¨¡å‹
    if os.path.exists(model_save_path):
        print(f"--- å‘ç°å·²å­˜åœ¨çš„æ¨¡å‹ï¼Œä» {model_save_path} åŠ è½½ ---")
        model = PPO.load(model_save_path, env=vec_env, tensorboard_log=log_dir)
    else:
        print("--- æœªå‘ç°å·²å­˜åœ¨çš„æ¨¡å‹ï¼Œåˆ›å»ºæ–°çš„ Cython ä¼˜åŒ–æ¨¡å‹ ---")
        policy_kwargs = dict(
            activation_fn=th.nn.ReLU,
            net_arch=dict(pi=[128, 128, 128], vf=[128, 128, 128])
        )
        model = PPO(
            ActorCriticPolicy, 
            vec_env, 
            policy_kwargs=policy_kwargs,
            n_steps=n_steps,
            n_epochs=10,
            batch_size=256,
            gamma=0.99,
            gae_lambda=0.95,
            clip_range=0.2,
            ent_coef=0.01,
            learning_rate=3e-4,
            verbose=1,
            tensorboard_log=log_dir,
            device="cpu"
        )

    print(f"Using {model.device} device")
    
    print("="*60)
    print("ğŸš€ Cython ä¼˜åŒ–ç‰ˆæœ¬æ€§èƒ½ç‰¹æ€§ (å½“å‰ä¸ºä¸²è¡Œæ¨¡å¼):")
    print("    â€¢ æ¸¸æˆæ‰§è¡Œé€Ÿåº¦: ~750 å±€/ç§’ (æ¯”åŸç‰ˆå¿« 4x)")
    print("    â€¢ æ­¥æ‰§è¡Œé€Ÿåº¦: ~32,000 æ­¥/ç§’ (æ¯”åŸç‰ˆå¿« 4x)")
    print("    â€¢ å¹³å‡æ¸¸æˆæ—¶é—´: ~1.3ms (æ¯”åŸç‰ˆå‡å°‘ 75%)")
    print("    â€¢ æ³¨æ„: DummyVecEnv ç¦ç”¨äº†å¹¶è¡Œï¼Œæ€»ååé‡ä¼šä½äº SubprocVecEnv")
    print("="*60)
    
    print("--- å¼€å§‹æˆ–ç»§ç»­ä½¿ç”¨ Cython ä¼˜åŒ–ç¯å¢ƒè®­ç»ƒ ---")
    
    callback = StatsCallback(verbose=1)
    
    log_name = "PPO_run"
    
    try:
        model.learn(
            total_timesteps=total_timesteps,
            callback=callback,
            tb_log_name=log_name,
            reset_num_timesteps=not os.path.exists(model_save_path)
        )
    except Exception as e:
        print(f"--- è®­ç»ƒè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {e} ---")
        emergency_path = os.path.join(log_dir, "emergency_save_model.zip")
        print(f"--- ç´§æ€¥ä¿å­˜æ¨¡å‹è‡³ {emergency_path} ---")
        model.save(emergency_path)
        raise
    finally:
        print("--- è®­ç»ƒå®Œæˆï¼Œä¿å­˜æœ€ç»ˆæ¨¡å‹ ---")
        model.save(model_save_path)
        vec_env.close()

if __name__ == '__main__':
    main()