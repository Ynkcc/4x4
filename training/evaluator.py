# training/evaluator.py

import os
import time
import numpy as np
from tqdm import tqdm

# å¯¼å…¥æœ¬åœ°æ¨¡å—
from sb3_contrib import MaskablePPO
from game.environment import GameEnvironment
from utils.constants import EVALUATION_GAMES

class EvaluationAgent:
    """ä¸€ä¸ªç®€å•çš„åŒ…è£…ç±»ï¼Œç”¨äºåœ¨è¯„ä¼°æ—¶åŠ è½½å’Œä½¿ç”¨æ¨¡å‹ã€‚"""
    def __init__(self, model_path: str):
        # ä½¿ç”¨'auto'è®©stable-baselines3è‡ªåŠ¨é€‰æ‹©è®¾å¤‡ (CPUæˆ–GPU)
        self.model = MaskablePPO.load(model_path, device='auto')
        # ä»è·¯å¾„ä¸­æå–æ¨¡å‹åç§°ï¼Œç”¨äºæ—¥å¿—è¾“å‡º
        self.name = os.path.basename(model_path)

    def predict(self, observation, action_masks, deterministic=True):
        """ä½¿ç”¨åŠ è½½çš„æ¨¡å‹è¿›è¡Œé¢„æµ‹ã€‚"""
        action, _ = self.model.predict(
            observation,
            action_masks=action_masks,
            deterministic=deterministic
        )
        return int(action), None

def _play_one_game(env: GameEnvironment, red_player: EvaluationAgent, black_player: EvaluationAgent, seed: int) -> int:
    """
    è¿›è¡Œä¸€å±€å®Œæ•´çš„æ¸¸æˆã€‚

    Args:
        env: æ¸¸æˆç¯å¢ƒå®ä¾‹ã€‚
        red_player: æ§åˆ¶çº¢æ–¹ï¼ˆç©å®¶1ï¼‰çš„Agentã€‚
        black_player: æ§åˆ¶é»‘æ–¹ï¼ˆç©å®¶-1ï¼‰çš„Agentã€‚
        seed: ç”¨äºé‡ç½®ç¯å¢ƒçš„éšæœºç§å­ï¼Œä»¥ç¡®ä¿æ£‹ç›˜å¸ƒå±€ç›¸åŒã€‚

    Returns:
        æ¸¸æˆç»“æœ (1: çº¢æ–¹èƒœ, -1: é»‘æ–¹èƒœ, 0: å¹³å±€)ã€‚
    """
    # ä½¿ç”¨æŒ‡å®šçš„ç§å­é‡ç½®ç¯å¢ƒ
    obs, info = env.reset(seed=seed)
    
    while True:
        # åˆ¤æ–­å½“å‰è½®åˆ°å“ªä¸ªç©å®¶
        current_player_agent = red_player if env.current_player == 1 else black_player
        
        # è·å–å½“å‰ç©å®¶çš„åˆæ³•åŠ¨ä½œæ©ç 
        action_mask = env.action_masks()
        
        # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰åˆæ³•çš„åŠ¨ä½œ
        if not np.any(action_mask):
            # å¦‚æœå½“å‰ç©å®¶æ— æ£‹å¯èµ°ï¼Œåˆ™å¯¹æ‰‹è·èƒœ
            return -env.current_player

        # Agentæ ¹æ®å½“å‰è§‚å¯Ÿå’ŒåŠ¨ä½œæ©ç é¢„æµ‹ä¸‹ä¸€æ­¥åŠ¨ä½œ
        action, _ = current_player_agent.predict(obs, action_masks=action_mask)
        
        # ä½¿ç”¨ç¯å¢ƒçš„å†…éƒ¨å‡½æ•°æ‰‹åŠ¨åº”ç”¨åŠ¨ä½œï¼Œè¿™ä¸ä¼šè§¦å‘å¯¹æ‰‹çš„è‡ªåŠ¨å›åˆ
        # è¿™ç§æ–¹å¼ç»™äºˆæˆ‘ä»¬å®Œå…¨çš„æ§åˆ¶æƒï¼Œé€‚ç”¨äºè¯„ä¼°åœºæ™¯
        _, terminated, truncated, winner = env._internal_apply_action(action)
        
        # æ£€æŸ¥æ¸¸æˆæ˜¯å¦ç»“æŸ
        if terminated or truncated:
            return winner
        
        # æ‰‹åŠ¨åˆ‡æ¢ç©å®¶
        env.current_player *= -1
        # è·å–åˆ‡æ¢åæ–°ç©å®¶çš„è§‚å¯ŸçŠ¶æ€
        obs = env.get_state()

def evaluate_models(challenger_path: str, main_opponent_path: str) -> float:
    """
    ã€é•œåƒå¯¹å±€è¯„ä¼°ç‰ˆã€‘è¯„ä¼°æŒ‘æˆ˜è€…æ¨¡å‹å¯¹é˜µä¸»å®°è€…æ¨¡å‹çš„è¡¨ç°ã€‚
    é€šè¿‡è¿›è¡Œæˆå¯¹çš„é•œåƒæ¯”èµ›æ¥è·å¾—æ›´å…¬å¹³ã€æ›´å¯ä¿¡çš„èƒœç‡ã€‚

    Args:
        challenger_path: æŒ‘æˆ˜è€…æ¨¡å‹çš„ .zip æ–‡ä»¶è·¯å¾„ã€‚
        main_opponent_path: ä¸»å®°è€…ï¼ˆå½“å‰æœ€å¼ºï¼‰æ¨¡å‹çš„ .zip æ–‡ä»¶è·¯å¾„ã€‚

    Returns:
        æŒ‘æˆ˜è€…æ¨¡å‹çš„èƒœç‡ (èŒƒå›´: 0.0 åˆ° 1.0)ã€‚
    """
    challenger_name = os.path.basename(challenger_path)
    main_name = os.path.basename(main_opponent_path)
    print(f"\n---  âš”ï¸  é•œåƒå¯¹å±€è¯„ä¼°å¼€å§‹: (æŒ‘æˆ˜è€…) {challenger_name} vs (ä¸»å®°è€…) {main_name} ---")

    # 1. åŠ è½½æ¨¡å‹
    try:
        challenger = EvaluationAgent(challenger_path)
        main_opponent = EvaluationAgent(main_opponent_path)
    except Exception as e:
        print(f"âŒ åŠ è½½æ¨¡å‹å¤±è´¥: {e}")
        # å¦‚æœæ¨¡å‹åŠ è½½å¤±è´¥ï¼Œè¿”å›0.0èƒœç‡ï¼Œé˜²æ­¢è®­ç»ƒä¸­æ–­
        return 0.0

    # 2. åˆå§‹åŒ–ç¯å¢ƒå’Œè®¡åˆ†æ¿
    # åªéœ€è¦ä¸€ä¸ªå•ç‹¬çš„ç¯å¢ƒå®ä¾‹ï¼Œåœ¨å¾ªç¯ä¸­é‡å¤ä½¿ç”¨
    eval_env = GameEnvironment()
    
    # æ ¹æ®å¸¸é‡è®¡ç®—å¯¹å±€ç»„æ•°ã€‚æ¯ç»„åŒ…å«2å±€é•œåƒæ¯”èµ›ã€‚
    # ä½¿ç”¨ // ç¡®ä¿ç»“æœä¸ºæ•´æ•°
    num_groups = EVALUATION_GAMES // 2
    
    # è®¡åˆ†æ¿ (ä»æŒ‘æˆ˜è€…çš„è§†è§’)
    scores = {
        'challenger_wins': 0,
        'opponent_wins': 0,
        'draws': 0,
    }

    print(f"å°†è¿›è¡Œ {num_groups} ç»„é•œåƒå¯¹å±€ (æ€»è®¡ {num_groups * 2} å±€æ¸¸æˆ)")
    
    # 3. æ‰§è¡Œè¯„ä¼°å¾ªç¯
    # ä½¿ç”¨tqdmåˆ›å»ºè¿›åº¦æ¡ï¼Œæ–¹ä¾¿ç›‘æ§è¯„ä¼°è¿›åº¦
    for i in tqdm(range(num_groups), desc="é•œåƒè¯„ä¼°è¿›åº¦"):
        # ä¸ºæ¯ä¸€ç»„å¯¹å±€ç”Ÿæˆä¸€ä¸ªå”¯ä¸€çš„ã€å›ºå®šçš„ç§å­ï¼Œç¡®ä¿ä¸¤å±€æ¯”èµ›çš„åˆå§‹çŠ¶æ€å®Œå…¨ç›¸åŒ
        game_seed = int(time.time_ns() + i) % (2**32 - 1)

        # --- ç¬¬ä¸€å±€: æŒ‘æˆ˜è€…æ‰§çº¢ vs ä¸»å®°è€…æ‰§é»‘ ---
        winner_1 = _play_one_game(eval_env, red_player=challenger, black_player=main_opponent, seed=game_seed)
        if winner_1 == 1: # çº¢æ–¹(æŒ‘æˆ˜è€…)è·èƒœ
            scores['challenger_wins'] += 1
        elif winner_1 == -1: # é»‘æ–¹(ä¸»å®°è€…)è·èƒœ
            scores['opponent_wins'] += 1
        else: # å¹³å±€
            scores['draws'] += 1

        # --- ç¬¬äºŒå±€: ä¸»å®°è€…æ‰§çº¢ vs æŒ‘æˆ˜è€…æ‰§é»‘ (é•œåƒå¯¹å±€) ---
        winner_2 = _play_one_game(eval_env, red_player=main_opponent, black_player=challenger, seed=game_seed)
        if winner_2 == 1: # çº¢æ–¹(ä¸»å®°è€…)è·èƒœ
            scores['opponent_wins'] += 1
        elif winner_2 == -1: # é»‘æ–¹(æŒ‘æˆ˜è€…)è·èƒœ
            scores['challenger_wins'] += 1
        else: # å¹³å±€
            scores['draws'] += 1
            
    eval_env.close()

    # 4. è®¡ç®—å¹¶æ‰“å°ç»“æœ
    # è®¡ç®—ç”¨äºèƒœç‡ç»Ÿè®¡çš„æ€»æœ‰æ•ˆå±€æ•°ï¼ˆæ’é™¤å¹³å±€ï¼‰
    total_decisive_games = scores['challenger_wins'] + scores['opponent_wins']
    
    # è®¡ç®—æŒ‘æˆ˜è€…èƒœç‡ï¼Œå¦‚æœåˆ†æ¯ä¸º0åˆ™èƒœç‡ä¸º0
    win_rate = scores['challenger_wins'] / total_decisive_games if total_decisive_games > 0 else 0.0

    print(f"\n--- ğŸ“Š è¯„ä¼°ç»“æŸ: å…±è¿›è¡Œäº† {num_groups * 2} å±€æ¸¸æˆ ---")
    print(f"    æŒ‘æˆ˜è€…æˆ˜ç»©: {scores['challenger_wins']}èƒœ / {scores['opponent_wins']}è´Ÿ / {scores['draws']}å¹³")
    print(f"    æŒ‘æˆ˜è€…èƒœç‡ (èƒœ / (èƒœ+è´Ÿ)): {win_rate:.2%}")
    
    return win_rate