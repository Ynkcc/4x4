# src_code/utils/constants.py

import os
import torch

# ==============================================================================
# --- 1. 核心路径与目录配置 ---
# ==============================================================================
# 项目根目录
ROOT_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))

# 训练输出的主目录 (所有模型、日志和评估结果都将保存在这里)
SELF_PLAY_OUTPUT_DIR = os.path.join(ROOT_DIR, "models", "self_play_final")

# 对手模型池目录 (由回调函数管理)
OPPONENT_POOL_DIR = os.path.join(SELF_PLAY_OUTPUT_DIR, "opponent_pool")

# TensorBoard 日志路径 (Ray Tune 会在此目录下创建实验文件夹)
TENSORBOARD_LOG_DIR = SELF_PLAY_OUTPUT_DIR


# ==============================================================================
# --- 2. RLlib 训练与环境配置 ---
# ==============================================================================
# 训练总迭代次数 (一次 `algo.train()` 算一次迭代)
TRAINING_ITERATIONS = 1000

# Ray Rollout Workers 的数量 (并行环境的数量)
NUM_WORKERS = 4  # 根据你的 CPU 核心数调整, 推荐为 CPU核心数 - 1

# 使用的 GPU 数量 (主训练器使用)
NUM_GPUS = 1 if torch.cuda.is_available() else 0

# 每个 Worker 使用的 GPU 数量 (设为 0 表示 Worker 使用 CPU)
NUM_GPUS_PER_WORKER = 0

# ==============================================================================
# --- 3. PPO 算法超参数 (RLlib Config) ---
# ==============================================================================
# 学习率
LEARNING_RATE = 1e-4

# 训练批次大小 (所有 Worker 收集的数据总和)
TRAIN_BATCH_SIZE = 4096

# SGD (随机梯度下降) 的 mini-batch 大小
SGD_MINIBATCH_SIZE = 256

# 每次训练迭代中，对采集到的数据进行优化的轮数
NUM_SGD_ITER = 20

# 熵系数，鼓励探索
ENTROPY_COEFF = 0.01

# PPO 裁剪参数
CLIP_PARAM = 0.2


# ==============================================================================
# --- 4. 自我对弈与评估超参数 ---
# ==============================================================================
# 每轮评估需要的游戏总局数
EVALUATION_GAMES = 100

# 挑战者晋级为新对手的胜率阈值
EVALUATION_THRESHOLD = 0.55

# 默认 Elo 评分
ELO_DEFAULT = 1500

# Elo K因子 (影响Elo评分变化的幅度)
ELO_K_FACTOR = 32

# 对手采样温度参数 (值越小，越倾向于选择 Elo 相近的对手)
ELO_WEIGHT_TEMPERATURE = 100.0

# RLlib 策略字典中的主策略 ID
MAIN_POLICY_ID = "main_policy"

# RLlib 策略字典中的对手策略 ID 前缀
OPPONENT_POLICY_ID_PREFIX = "opponent_"

# 检查点保存频率 (每 N 次迭代保存一次)
CHECKPOINT_FREQ = 20


# ==============================================================================
# --- 5. 对手池大小配置 ---
# ==============================================================================
# 长期对手池大小 (保存具有里程碑意义的模型)
LONG_TERM_POOL_SIZE = 5

# 短期对手池大小 (保存最近生成的模型)
SHORT_TERM_POOL_SIZE = 10


# ==============================================================================
# --- 6. 环境与调试相关 ---
# ==============================================================================
# 状态堆叠大小 (模型会看到过去 N 帧的状态)
STATE_STACK_SIZE = 4

# 是否在训练时使用固定的随机种子 (用于复现实验)
USE_FIXED_SEED_FOR_TRAINING = False

# 固定的种子值
FIXED_SEED_VALUE = 42


# ==============================================================================
# --- 7. 对手池大小配置 ---
# ==============================================================================
# 长期对手池大小
LONG_TERM_POOL_MAX_SIZE = 5
# 短期对手池大小
SHORT_TERM_POOL_MAX_SIZE = 10
