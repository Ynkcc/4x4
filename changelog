

再生成一个正式开始继续训练的训练脚本，训练3，000，000步

同时由于环境以发生变更，模型的网络结构也需要发生变更。帮助生成一个迁移脚本。复制并冻结原有模型的参数，训练1，000,000

将代码中的翻开全部棋子的逻辑，改为一个标识符，用于表示使用全明子游戏

继续修改
我希望进行增量式的状态更新，而不是每次重新计算，以减少计算量。然后每次被调get_state时，直接返回一个状态向量的深拷贝。当每次有action时触发状态更新。
由于玩家-1，1双方的视角并不相同，也许需要准备两个不同的变量。并更新这两个变量

针对环境作出以下修改
当前状态的威胁图层 (Threat Plane): 一个4x4的二元图层，明确标记出棋盘上所有正处于对手攻击范围内的位置。
行动机会向量：向量大小与行动空间相当且一一对应，如果该行动能够吃子则设为1
行动威胁向量：向量大小与行动空间相当且一一对应，如果该行动将导致该棋子落入对手攻范围则设为1
行动机会向量和行动威胁向量，只处理有效动作
死亡棋子计数，调整到二元表示。例如，用[1, 1]表示两个兵都已死亡，[1, 0]表示1个兵已死亡
