# src_code/hyperparameter_tuning.py

import os
import warnings
import optuna
import time

# ç¦ç”¨TensorFlowè­¦å‘Š
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'
warnings.filterwarnings('ignore', category=UserWarning, module='google.protobuf')

from stable_baselines3.common.env_util import make_vec_env
from stable_baselines3.common.vec_env import DummyVecEnv
from sb3_contrib import MaskablePPO

# å¯¼å…¥é¡¹ç›®ä¸­çš„æ¨¡å—
from game.environment import GameEnvironment
from game.policy import CustomActorCriticPolicy
from training.evaluator import evaluate_models
from utils.constants import MAIN_OPPONENT_PATH, EVALUATION_GAMES, N_ENVS

# --- é…ç½® ---
# ä¼˜åŒ–è¯•éªŒçš„æ€»æ¬¡æ•°
N_TRIALS = 50
# æ¯æ¬¡è¯•éªŒä¸­ï¼Œæ¨¡åž‹è®­ç»ƒçš„æ€»æ­¥æ•° (ä¸ºäº†å¿«é€Ÿè¿­ä»£ï¼Œå¯ä»¥è®¾ç½®å¾—æ¯”ä¸»è®­ç»ƒå°)
TRAINING_TIMESTEPS_PER_TRIAL = 2048 * 8 
# è¯„ä¼°æ—¶ä½¿ç”¨çš„åŸºå‡†æ¨¡åž‹
BASELINE_MODEL_PATH = MAIN_OPPONENT_PATH
# ä¼˜åŒ–ç»“æžœå­˜å‚¨è·¯å¾„
TUNING_OUTPUT_DIR = "./tuning_results/"

def objective(trial: optuna.Trial) -> float:
    """
    Optunaçš„ç›®æ ‡å‡½æ•°ï¼Œç”¨äºŽå®šä¹‰ã€è®­ç»ƒå’Œè¯„ä¼°ä¸€ç»„è¶…å‚æ•°ã€‚
    """
    print(f"\n{'='*50}\n trial {trial.number}/{N_TRIALS} is starting...\n{'='*50}")
    
    # --- 1. å®šä¹‰è¶…å‚æ•°çš„æœç´¢ç©ºé—´ ---
    # PPO æ ¸å¿ƒå‚æ•°
    learning_rate = trial.suggest_float("learning_rate", 1e-5, 1e-3, log=True)
    n_steps = trial.suggest_categorical("n_steps", [512, 1024, 2048, 4096])
    batch_size = trial.suggest_categorical("batch_size", [128, 256, 512, 1024])
    n_epochs = trial.suggest_int("n_epochs", 5, 20)
    clip_range = trial.suggest_categorical("clip_range", [0.1, 0.2, 0.3, 0.4])
    gae_lambda = trial.suggest_float("gae_lambda", 0.9, 0.99)
    ent_coef = trial.suggest_float("ent_coef", 0.0, 0.1)
    vf_coef = trial.suggest_float("vf_coef", 0.2, 0.8)

    # è‡ªå®šä¹‰ç½‘ç»œæž¶æž„å‚æ•°
    net_features_dim = trial.suggest_categorical("net_features_dim", [128, 256, 512])
    net_num_res_blocks = trial.suggest_int("net_num_res_blocks", 2, 8)
    net_num_hidden_channels = trial.suggest_categorical("net_num_hidden_channels", [32, 64, 128])
    
    # ç¡®ä¿ n_steps > batch_size
    if n_steps < batch_size:
        # Optuna V2. Pruning.
        # Optuna V3. trial.report() is used for pruning and report() returns void.
        # See https://optuna.readthedocs.io/en/stable/faq.html#how-can-i-implement-pruning-in-my-objective-function
        raise optuna.exceptions.TrialPruned()


    # --- 2. ä½¿ç”¨å»ºè®®çš„è¶…å‚æ•°åˆ›å»ºçŽ¯å¢ƒå’Œæ¨¡åž‹ ---
    run_name = f"trial_{trial.number}_{int(time.time())}"
    trial_model_save_path = os.path.join(TUNING_OUTPUT_DIR, f"{run_name}.zip")

    try:
        # åˆ›å»ºè®­ç»ƒçŽ¯å¢ƒ (è¿™é‡Œä¸ºäº†ç®€å•ï¼Œä¸ä½¿ç”¨å¯¹æ‰‹æ± ï¼Œç›´æŽ¥è‡ªæˆ‘å¯¹å¼ˆ)
        env = make_vec_env(GameEnvironment, n_envs=N_ENVS, vec_env_cls=DummyVecEnv)
        
        model = MaskablePPO(
            policy=CustomActorCriticPolicy,
            env=env,
            learning_rate=learning_rate,
            n_steps=n_steps,
            batch_size=batch_size,
            n_epochs=n_epochs,
            clip_range=clip_range,
            gae_lambda=gae_lambda,
            ent_coef=ent_coef,
            vf_coef=vf_coef,
            device='auto',
            verbose=0, # åœ¨è°ƒä¼˜æ—¶å…³é—­è¯¦ç»†æ—¥å¿—
            policy_kwargs={
                'features_extractor_kwargs': {
                    'features_dim': net_features_dim,
                    'num_res_blocks': net_num_res_blocks,
                    'num_hidden_channels': net_num_hidden_channels
                }
            }
        )

        # --- 3. è®­ç»ƒæ¨¡åž‹ ---
        print(f"Training trial {trial.number} for {TRAINING_TIMESTEPS_PER_TRIAL} timesteps...")
        model.learn(total_timesteps=TRAINING_TIMESTEPS_PER_TRIAL, progress_bar=True)
        model.save(trial_model_save_path)
        
        env.close() # æ¸…ç†çŽ¯å¢ƒ

        # --- 4. è¯„ä¼°æ¨¡åž‹ ---
        # ç¡®ä¿åŸºå‡†æ¨¡åž‹å­˜åœ¨
        if not os.path.exists(BASELINE_MODEL_PATH):
            raise FileNotFoundError(f"åŸºå‡†æ¨¡åž‹ {BASELINE_MODEL_PATH} ä¸å­˜åœ¨ï¼Œæ— æ³•è¿›è¡Œè¯„ä¼°ã€‚")

        print(f"Evaluating trial {trial.number} against baseline model...")
        # evaluate_models è¿”å›žæŒ‘æˆ˜è€…çš„èƒœçŽ‡
        win_rate = evaluate_models(
            challenger_path=trial_model_save_path,
            main_opponent_path=BASELINE_MODEL_PATH,
            show_progress=False # åœ¨è°ƒä¼˜æ—¶å…³é—­è¿›åº¦æ¡
        )
        print(f"Trial {trial.number} result: win_rate = {win_rate:.2%}")

    except Exception as e:
        print(f"Trial {trial.number} failed with error: {e}")
        # å¦‚æžœå‡ºé”™ï¼Œè¿”å›žä¸€ä¸ªå¾ˆå·®çš„ç»“æžœ
        return 0.0
    finally:
        # æ¸…ç†æœ¬æ¬¡è¯•éªŒäº§ç”Ÿçš„æ¨¡åž‹æ–‡ä»¶
        if os.path.exists(trial_model_save_path):
            os.remove(trial_model_save_path)
    
    return win_rate


if __name__ == '__main__':
    # --- ä¸»ç¨‹åºå…¥å£ ---
    print("ðŸš€ Starting hyperparameter tuning with Optuna...")

    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    os.makedirs(TUNING_OUTPUT_DIR, exist_ok=True)
    
    # åˆ›å»ºä¸€ä¸ªç ”ç©¶(study)ï¼Œç›®æ ‡æ˜¯æœ€å¤§åŒ–èƒœçŽ‡
    # TPE (Tree-structured Parzen Estimator) æ˜¯ä¸€ç§é«˜æ•ˆçš„é‡‡æ ·ç®—æ³•
    study = optuna.create_study(direction="maximize", sampler=optuna.samplers.TPESampler())
    
    try:
        # è¿è¡Œä¼˜åŒ–
        study.optimize(objective, n_trials=N_TRIALS)
    except KeyboardInterrupt:
        print("ðŸ›‘ Tuning process interrupted by user.")
    
    # --- æ‰“å°ä¼˜åŒ–ç»“æžœ ---
    print("\n" + "="*50)
    print("          ðŸ“Š Hyperparameter Tuning Results ðŸ“Š")
    print("="*50)
    print(f"Number of finished trials: {len(study.trials)}")
    
    print("\n--- Best Trial ---")
    best_trial = study.best_trial
    print(f"  Value (Win Rate): {best_trial.value:.4f}")
    
    print("  Params: ")
    for key, value in best_trial.params.items():
        print(f"    {key}: {value}")
        
    print("\n--- All Trials Summary ---")
    df = study.trials_dataframe(attrs=("number", "value", "params", "state"))
    print(df)
    
    print(f"\nâœ… Tuning finished! You can find the best parameters above.")
    print("To visualize results, you can use optuna-dashboard:")
    print("  pip install optuna-dashboard")
    print(f"  optuna-dashboard sqlite:///{study.storage.get_url(study.study_name)}")